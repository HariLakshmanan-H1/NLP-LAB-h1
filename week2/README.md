# ğŸ“˜ Bigram Association Analysis using t-test and Chi-square (NLP)

This project demonstrates how **statistical hypothesis tests** can be applied to **Natural Language Processing (NLP)** for discovering **meaningful word associations (collocations)**.

It compares:

- **Manual statistical implementations**
- **NLTKâ€™s out-of-the-box association measures**

and visualizes both **t-test** and **Ï‡Â²-test** intuitively.

---

## ğŸ¯ Objective

To answer the question:

> _Do two words occur together more often than expected by chance?_

Using:

- **Studentâ€™s t-test** â†’ consistency against noise
- **Chi-square test (Ï‡Â²)** â†’ incompatibility with independence

---

## ğŸ§  Conceptual Intuition

| Test    | What it Measures            | Intuition |
| ------- | --------------------------- | --------- |
| t-test  | Signal vs noise             | ğŸ¯ vs â˜ï¸  |
| Ï‡Â²-test | Surprise under independence | ğŸ˜¬Â² Ã· ğŸ“  |

Both tests answer **different statistical questions**, so both are useful in NLP collocation discovery.

---

## ğŸ“‚ Input Data

- Input file: **Excel (.xlsx)**
- Each row contains **one sentence**
- Example:

  ```
  Sastra University main campus
  Nuclear fission laboratory
  ```

---

## ğŸ”„ Processing Pipeline

### 1ï¸âƒ£ Data Loading

- Reads sentences from an Excel file
- Ignores empty or invalid rows

### 2ï¸âƒ£ Text Preprocessing

- Lowercasing
- Punctuation removal
- Whitespace normalization
- Tokenization (NLTK `word_tokenize`)
- Sentence-level token preservation

### 3ï¸âƒ£ Token Aggregation

- Flattens tokens into a single corpus
- Computes:
  - Word frequencies
  - Bigram frequencies
  - Trigram frequencies

---

## ğŸ“ Statistical Measures Implemented

### âœ… Manual t-test (Bigram)

Based on **Bernoulli variance**:

[
t = \frac{\bar{x} - \mu}{\sqrt{\frac{s^2}{N}}}
]

Where:

- (\bar{x}) = observed bigram probability
- (\mu) = expected probability under independence
- (s^2 = \bar{x}(1-\bar{x}))
- (N) = total bigram positions

This version explicitly models **sampling variability**.

---

### âœ… Manual Ï‡Â²-test (Bigram)

Uses a **2Ã—2 contingency table**:

|     | wâ‚‚  | Â¬wâ‚‚ |
| --- | --- | --- |
| wâ‚  | Oâ‚â‚ | Oâ‚â‚‚ |
| Â¬wâ‚ | Oâ‚‚â‚ | Oâ‚‚â‚‚ |

[
\chi^2 = \sum \frac{(O - E)^2}{E}
]

Measures **how incompatible the observation is with independence**.

---

### ğŸ§° NLTK Out-of-the-Box Measures

The project also uses:

- `BigramCollocationFinder`
- `BigramAssocMeasures.student_t`
- `BigramAssocMeasures.chi_sq`

This allows **direct comparison** between:

- Hand-derived statistics
- Library implementations

---

## ğŸ“Š Output Report

A comparison table like:

| Bigram            | Frequency | Manual t | NLTK t | Manual Ï‡Â² | NLTK Ï‡Â² |
| ----------------- | --------- | -------- | ------ | --------- | ------- |
| sastra university | 32        | 5.25     | 5.09   | 303.13    | 303.13  |
| main campus       | 1         | 0.99     | 0.99   | 104.60    | 104.60  |

This confirms:

- Correctness of manual implementations
- Expected numerical agreement with NLTK

---

## ğŸ“ˆ Visualization

### ğŸ”¹ t-test Visualization

- Studentâ€™s t-distribution
- Observed bigram t-values plotted as vertical markers
- Critical value (Î± = 0.01) marked
- Acceptance and rejection regions shaded

Interpretation:

- Right tail â†’ strong association
- Near zero â†’ noise-level co-occurrence

---

### ğŸ”¹ Ï‡Â²-test Visualization

- Chi-square distribution (df = 1)
- Observed Ï‡Â² values overlaid
- Critical Ï‡Â² threshold (3.84 for Î± = 0.05)
- Rejection region shaded

Interpretation:

- Large Ï‡Â² â†’ independence assumption collapses
- Small Ï‡Â² â†’ nothing surprising

---

## ğŸ§ª Example Bigram Cases

| Bigram            | Interpretation              |
| ----------------- | --------------------------- |
| sastra university | Strong semantic collocation |
| main campus       | Moderate association        |
| nuclear fission   | Absent or unrelated         |

---

## ğŸ“¦ Dependencies

Install the required libraries:

```bash
pip install pandas numpy nltk scipy matplotlib
```

Additionally, download NLTK resources:

```python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
```

---

## ğŸ§  Who This Is For

- NLP students learning **statistical collocations**
- Anyone transitioning from **formulae â†’ intuition**
- Researchers wanting **transparent implementations**
- Teaching demonstrations for hypothesis testing in NLP

---

## âœ¨ Key Takeaway

> **t-test asks:**
> â€œIs this co-occurrence consistently stronger than noise?â€

> **Ï‡Â²-test asks:**
> â€œHow shocked should I be if independence were true?â€

Using both gives a **complete statistical picture** of word association.

---

_Optional next steps:_

- PMI vs t vs Ï‡Â² comparison
- Entropy-based association
- Collocation ranking dashboard
- Paper-ready methodology section
